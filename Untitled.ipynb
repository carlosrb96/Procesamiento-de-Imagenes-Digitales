{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtención de dibujos mediante el procesamiento digital de imágenes\n",
    "### Basado en el artículo \"Combining Sketch and Tone for Pencil Drawing Production\" por Cewu Lu, Li Xu y Jiaya Jia\n",
    "La web del proyecto se puede encontrar aquí: \n",
    "http://www.cse.cuhk.edu.hk/leojia/projects/pencilsketch/pencil_drawing.htm\n",
    "\n",
    "PDF del artículo: \n",
    "http://www.cse.cuhk.edu.hk/leojia/projects/pencilsketch/npar12_pencil.pdf\n",
    "\n",
    "En este notebook, vamos a implementar en python un algoritmo que siga el planteamiento de este artículo. Para ello, vamos a dividir el flujo de trabajo en cuatro etapas:\n",
    "1. Obtener el trazado/boceto de la imagen.\n",
    "2. Generar un mapa de tonalidades de la imagen.\n",
    "3. Aplicar la textura de lápiz al mapa de tonalidades.\n",
    "4. Fusionar el boceto con el mapa de tonalidades texturizado para obtener el dibujo final.\n",
    "\n",
    "Para la primera etapa, necesitamos obtener los bordes del objeto/s que resalten más en la imagen. Ese sería nuestro punto de partida para obtener el trazo principal del boceto.\n",
    "Para ello, primero debemos suavizar la imagen para evitar que se resalten bordes innecesarios, como puede ser ruido que tenga la imagen o bien detalles de la imagen que, para nuestro procesado, son irrelevantes o incluso pueden alterar el resultado final.\n",
    "\n",
    "Seguidamente obtenemos el gradiente de la imagen sobre el eje X y el eje Y. El operador gradiente nos devolverá un vector con la dirección de máxima variabilidad de intensidad y su nivel de variación. Para calcular el gradiente nos ayudamos de una máscara, que será un filtro que procesará cada pixel para determinar si el pixel compone parte de un borde o no. Usaremos la máscara de Sobel, pero se podrían usar otras como la de Prewitt o Roberts:\n",
    "\n",
    "$$ G = \\sqrt{(\\partial_xI)^2 + (\\partial_yI)^2} $$\n",
    "\n",
    "Después de obtener los bordes, tenemos lo necesario para procesar esos bordes y convertirlos en pequeños trazos, simulando los trazos a mano alzada de un dibujante. Para ello, vamos a descomponer nuestra imagen gradiente y a clasificar los bordes según la dirección que tienen. Para este proceso nos ayudaremos de unas máscaras con una línea recta en su centro y dispuesta en diferentes direcciones, denotadas por:\n",
    "\n",
    "$ L_i, i \\in [1..8] $. \n",
    "\n",
    "Usaremos el operador de convolución para aplicar cada máscara a nuestra imagen gradiente y así obtener como resultado una lista de matrices con la superposición de cada máscara con la imagen gradiente.\n",
    "\n",
    "$$ G_i = L_i \\otimes G $$\n",
    "\n",
    "Iteraremos sobre cada elemento de cada matriz resultante evaluando qué matriz tiene el mayor valor para ese elemento i-ésimo, para así obtener un \"mapa\" donde cada elemento del mapa nos indicará la dirección o el ángulo que tiene que tomar el pixel en esa posición.\n",
    "La Clasificación final será una lista de n matrices, que corresponderán a las n direcciones o ángulos dados y dentro de cada una de ellas estarán los pixeles de la imagen gradiente que tengan la posición de los elementos del mapa de direcciones que tengan el mismo valor que la dirección de la matriz. En otro caso los pixeles tendrán valor 0.\n",
    "\n",
    "$$ C_i(p) =\n",
    "  \\begin{cases}\n",
    "    G(p)       & \\quad \\text{if } argmax_i(G_i(p))=i \\\\\n",
    "    0  & \\quad \\text{else}\n",
    "  \\end{cases}\n",
    "$$\n",
    "\n",
    "Cada una de las i matrices guardadas en la clasificación tiene guardados los pixeles y la posición que en el gradiente tienen una dirección i.\n",
    "Para, finalmente, obtener el boceto procesado, solo tenemos que realizar de nuevo la operación de convolución a las diferentes matrices de la clasificación por la máscara con la dirección correspondiente.\n",
    "\n",
    "$$ S' = \\sum_{i=1}^{8} L_i \\otimes C_i $$\n",
    "\n",
    "Esto hará que los trazos que se generen tengan un poco más de grosor. Finalmente se suman todas las matrices de la clasificación, se normalizan para que tengan valores entre [0-1] y se invierte para que los trazos se vean en negro sobre un fondo blanco. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import transform, exposure\n",
    "from scipy import signal, sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_trazado(img,tamkernel,num_direcciones=8,tam_masc_suavizado=5):\n",
    "#Suavizado de la imagen\n",
    "    img = cv2.GaussianBlur(img,(tam_masc_suavizado,tam_masc_suavizado),0)\n",
    "#Cálculo del gradiente usando Sobel\n",
    "    scale = 1\n",
    "    delta = 0\n",
    "    ddepth = cv2.CV_16S\n",
    "    altura = img.shape[0] #Número de filas \n",
    "    anchura = img.shape[1] #Número de columnas\n",
    "\n",
    "\n",
    "    grad_x = cv2.Sobel(img, ddepth, 1, 0, 1, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "    grad_y = cv2.Sobel(img, ddepth, 0, 1, 1, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "\n",
    "    abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "    abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "    #Obtención de la imagen gradiente final\n",
    "    G = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0) #Este es el valor G en la Fig. 2 del artículo\n",
    "\n",
    "    cv2.imshow('original', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.imshow('gradiente', G)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "#A partir de G calcularemos el clasificador C y posteriormente la forma en pinceladas S de nuestra imagen \n",
    "#Primero aplicaremos unas máscaras de tamaño tamkernel * 2 + 1. Esas máscaras consisten en una línea centrada\n",
    "#En diferentes ángulos\n",
    "\n",
    "    tamkernel = tamkernel * 2 + 1 \n",
    "    midkernel = tamkernel // 2\n",
    "    kernel = (tamkernel,tamkernel)\n",
    "    kernelh = np.zeros(kernel)\n",
    "    kernelh[midkernel,:] = 1 #Máscara línea horizontal\n",
    "    \n",
    "    #Aquí guardaremos las distintas convoluciones de las máscaras con nuestra  imagen procesada\n",
    "    res_map = np.zeros((altura, anchura, num_direcciones))     \n",
    "    for i in range(num_direcciones):\n",
    "        ker = transform.rotate(kernelh, (180 * i)/num_direcciones)\n",
    "        res_map[:,:,i] = signal.convolve2d(G,ker,mode ='same')\n",
    "        \n",
    "    #Aquí devuelve una matriz donde indicará el indice de la dirección donde se guarda el pixel de mayor valor\n",
    "    mapa_indices_maximo_pixel = np.argmax(res_map, axis=2)\n",
    "\n",
    "    C = np.zeros_like(res_map)\n",
    "\n",
    "    for i in range(num_direcciones):\n",
    "        #Aquí creamos las distintas clasificaciones del gradiente según la dirección que toma cada pixel\n",
    "        #Guardaremos en Ci los pixeles de G en las posiciones donde nuestro mapa de direcciones tenga el valor de la direccion i\n",
    "        #En otro caso será 0\n",
    "        C[:,:,i] = G * (mapa_indices_maximo_pixel == i)\n",
    "    \n",
    "    S_prima_separado = np.zeros_like(C)\n",
    "\n",
    "    #De nuevo volvemos a realizar la operación de convolución de nuestros Ci por la máscara de dirección i correspondiente\n",
    "    #Esto dará el aspecto de pequeños trazos a los bordes de nuestra imagen\n",
    "    for i in range(num_direcciones):\n",
    "        ker = transform.rotate(kernelh, (i * 180) / num_direcciones)\n",
    "        S_prima_separado[:,:,i] = signal.convolve2d(C[:,:,i], ker, mode='same')\n",
    "    \n",
    "    #Sumamos los resultados\n",
    "    S_prima = np.sum(S_prima_separado, axis=2)\n",
    "    \n",
    "    #Normalizamos el resultado para que los pixeles se muevan en el rango[0,1]\n",
    "    S_prima_normalizada = (S_prima - np.min(S_prima.ravel())) / (np.max(S_prima.ravel()) - np.min(S_prima.ravel()))\n",
    "    \n",
    "    #Invertimos nuestra imagen para que los trazos se vean negros sobre un fondo blanco, como si fuese un boceto\n",
    "    S = 1 - S_prima_normalizada\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('trafico.png',0)\n",
    "S = obtener_trazado(img,8,8)\n",
    "cv2.imshow('Trazado de la imagen', S)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que ya tenemos nuestro boceto, procedemos a hacer un ajuste en las tonalidades de nuestra imagen. Esto se hace para que los tonos de gris(claro,medio,oscuro) sean lo más parecidos a los tonos de gris que tiene un dibujo. Los investigadores del artículo argumentan que los dibujos hechos a mano, si se procesan y se observa el histograma, se puede ver como repiten un patrón concreto. Esto se debe a que, los dibujos hechos a mano alzada siempre tienen un factor común que afecta al histograma, un fondo blanco(el papel) que da una luminancia mayor, y los trazos hechos con lápices de grafito que dan ese tono de gris característico.\n",
    "\n",
    "Proponen entonces crear un modelo paramétrico con el cual ajustar la distribución de tonos de la imagen original para que tenga parecido a la distribución de tonos de un dibujo. Esto lo hacen uniendo 3 distribuciones de probabilidad distintas p1, p2 y p3, cada una enfocándose respectivamente en los tonos claro, medio y oscuro:\n",
    "\n",
    "$$ p(v) = \\frac{1}{Z}\\sum_{i=1}^{3}\\omega_ip_i(v) $$\n",
    "\n",
    "* Para los tonos claros, se usa una distribución Laplaciana: $$ p_1(v) =\n",
    "   \\begin{cases}\n",
    "       \\frac{1}{\\sigma_b}e^{-\\frac{1 - v}{\\sigma_b}}       & \\quad \\text{if } v \\leq 1 \\\\\n",
    "       0  & \\quad \\text{else}\n",
    "   \\end{cases} \n",
    "$$ Donde $\\sigma_b$ es la escala de la distribución.$$ $$\n",
    "\n",
    "* Para la capa media, se usan distribuciones uniformes: $$ p_2(v) =\n",
    "  \\begin{cases}\n",
    "    \\frac{1}{u_b - u_a}       & \\quad \\text{if } u_a \\leq v \\leq u_b \\\\\n",
    "    0  & \\quad \\text{else}\n",
    "  \\end{cases}\n",
    "$$ donde $u_a$, $u_b$ son los rangos de la distribución. $$ $$\n",
    "\n",
    "* Para los tonos oscuros, usamos una distribución Gaussiana: $$ p_3(v) = \\frac{1}{\\sqrt{2\\pi\\sigma_d}}e^{-\\frac{(v-\\mu_d)^2}{2\\sigma_d^2}} $$ donde $\\sigma_d$ es la escala de la distribución\n",
    "\n",
    "El resultado será un histograma del cual obtendremos(junto con el histograma de la imagen) una LUT(Look-Up Table), y procesaremos nuestra imagen con esa LUT, que no es más que ajustar los valores de los pixeles de la imagen según lo indique la tabla de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_tonalidad(img, w_group=0,pesos_prueba=None):\n",
    "    # Grupos de pesos para las diferentes tonalidades. 1ª fila tonalidad clara, 2ª tonalidad media, 3ª tonalidad oscura\n",
    "    #Estos pesos son los pesos ya definidos en el artículo.\n",
    "    if pesos_prueba != None:\n",
    "        w = pesos_prueba\n",
    "    else:\n",
    "        w_mat = np.array([[11, 37, 52],\n",
    "                     [29, 29, 42],\n",
    "                     [2, 22, 76]])\n",
    "        w = w_mat[w_group,:]\n",
    "    \n",
    "    #Parámetros definidos en el artículo\n",
    "    \n",
    "    u_b = 225\n",
    "    u_a = 105\n",
    "    sigma_b = 9\n",
    "    mu_d = 90\n",
    "    sigma_d = 11\n",
    "    \n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    \n",
    "    # Cálculo del nuevo histograma p(v)\n",
    "    num_pixel_vals = 256\n",
    "    p = np.zeros(num_pixel_vals)\n",
    "    for v in range(num_pixel_vals):\n",
    "        p1 = (1 / sigma_b) * np.exp(-(255 - v) / sigma_b) #Función de distribución para tonos claros\n",
    "        if (u_a <= v <= u_b):\n",
    "            p2 = 1 / (u_b - u_a)\n",
    "        else:                         #Función de distribución para tonos medios\n",
    "            p2 = 0\n",
    "            \n",
    "            #Función de distribución para tonos oscuros\n",
    "        p3 = (1 / np.sqrt(2 * np.pi * sigma_d)) * np.exp( (-np.square(v - mu_d)) / (2 * np.square(sigma_d)) )\n",
    "        \n",
    "        #Sumamos las distribuciones multiplicadas por los distintos pesos\n",
    "        p[v] = w[0] * p1 + w[1] * p2 + w[2] * p3 * 1/100\n",
    "    \n",
    "    p_normalizado = p/np.sum(p)\n",
    "    P = np.cumsum(p_normalizado)\n",
    "    h = cv2.calcHist([img],[0],None,[256],[0,256])\n",
    "    H = np.cumsum(h / np.sum(h))\n",
    "    lut = np.zeros_like(p)\n",
    "    for v in range(num_pixel_vals):\n",
    "        dist = np.abs(P - H[v])\n",
    "        argmin_dist = np.argmin(dist)\n",
    "        lut[v] = argmin_dist\n",
    "    lut_normalized = lut / num_pixel_vals\n",
    "    J = cv2.LUT(img,lut_normalized)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('trafico.png',0)\n",
    "J1 = ajustar_tonalidad(img,w_group=0)\n",
    "J2 = ajustar_tonalidad(img,w_group=1)\n",
    "J3 = ajustar_tonalidad(img,w_group=2)\n",
    "\n",
    "cv2.imshow('Imagen original', img)\n",
    "cv2.imshow('J1', J1)\n",
    "cv2.imshow('J2', J2)\n",
    "cv2.imshow('J3', J3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de haber obtenido nuestro mapa de tonos ajustado, el paso siguiente es dar textura a esos tonos. Como si fuera un dibujante, para que un dibujo a lápiz pueda conseguir una tonalidad concreta de gris, repiten un patrón de trazos sobre una zona concreta x veces. Los trazos del lápiz superpuestos generan el tono más oscuro o más claro que necesitemos y además dan cierta textura al dibujo.\n",
    "\n",
    "Para ello, los investigadores plantearon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_textura_lapiz(img, H, J):\n",
    "    \n",
    "    lamda = 0.2\n",
    "    altura = img.shape[0]\n",
    "    anchura = img.shape[1]\n",
    "    dim = (anchura,altura)\n",
    "    # Ajustamos nuestra H (textura de lápiz) y nuestra J(tonalidades) para que tengan el mismo tamaño y forma que nuestra imagen\n",
    "    H_res = cv2.resize(H,dim, interpolation=cv2.INTER_CUBIC)\n",
    "    H_res_reshaped = np.reshape(H_res, (altura * anchura, 1))\n",
    "    logH = np.log(H_res_reshaped)\n",
    "    \n",
    "    J_res = cv2.resize(J,dim, interpolation=cv2.INTER_CUBIC)\n",
    "    J_res_reshaped = np.reshape(J_res, (altura * anchura, 1))\n",
    "    logJ = np.log(J_res_reshaped)\n",
    "    \n",
    "    # Para poder realizar el conjugado del gradiente, primero necesitamos unas matrices dispersas\n",
    "    \n",
    "    logH_sparse = sparse.spdiags(logH.ravel(), 0, altura*anchura, altura*anchura) \n",
    "    e = np.ones((altura * anchura, 1))\n",
    "    ee = np.concatenate((-e,e), axis=1)\n",
    "    diags_x = [0, altura*anchura]\n",
    "    diags_y = [0, 1]\n",
    "\n",
    "    dx = sparse.spdiags(ee.T, diags_x, altura*anchura, altura*anchura)\n",
    "    dy = sparse.spdiags(ee.T, diags_y, altura*anchura, altura*anchura)\n",
    "    \n",
    "    # Calculamos A y b (para poder resolver nuestra ecuación lineal Ax = b)\n",
    "    A = lamda * ((dx @ dx.T) + (dy @ dy.T)) + logH_sparse.T @ logH_sparse\n",
    "    b = logH_sparse.T @ logJ\n",
    "    \n",
    "    # Procedemos a calcular el conjugado del gradiente\n",
    "    beta = sparse.linalg.cg(A, b, tol=1e-6, maxiter=60)\n",
    "    \n",
    "    # Ajustamos el resultado al tamaño de la imagen original\n",
    "    beta_reshaped = np.reshape(beta[0], (altura, anchura))\n",
    "    \n",
    "    # The final pencil texture map T\n",
    "    T = np.power(H_res, beta_reshaped)\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"trafico.png\",0)\n",
    "H = cv2.imread(\"pencil1.jpg\",0)\n",
    "S = obtener_trazado(img,8,8)\n",
    "J = ajustar_tonalidad(img,w_group=2)\n",
    "T = obtener_textura_lapiz(img,H,J)\n",
    "cv2.imshow('Dibujo final', T)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_textura_lapiz2(img, H, J,num_betas):\n",
    "    \n",
    "    altura = img.shape[0]\n",
    "    anchura = img.shape[1]\n",
    "    dim = (anchura,altura)\n",
    "    print(img.shape)\n",
    "\n",
    "    # Ajustamos nuestra H (textura de lápiz) y nuestra J(tonalidades) para que tengan el mismo tamaño y forma que nuestra imagen\n",
    "    H_res = cv2.resize(H,dim, interpolation=cv2.INTER_CUBIC)\n",
    "    print(H_res.shape)\n",
    "    H_normalizada = (H_res - np.min(H_res.ravel())) / (np.max(H_res.ravel()) - np.min(H_res.ravel()))\n",
    "    rows,cols = H_normalizada.shape\n",
    "    n=0.7\n",
    "    r=np.max(H_normalizada)\n",
    "    c=r/pow(r,n)\n",
    "    imgRaiz = np.zeros_like(H_normalizada)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            imgRaiz[i,j]=c*(pow(H_normalizada[i,j],n))\n",
    "    \n",
    "    h_res = cv2.GaussianBlur(imgRaiz,(3,3),0)\n",
    "    cv2.imshow('Raiz',imgRaiz)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.imshow('H_normalizada', H_normalizada)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    J_res = cv2.resize(J,dim, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow('J', J_res)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    res_map = np.zeros((altura, anchura, num_betas))\n",
    "    algo = np.ones_like(res_map)\n",
    "    \n",
    "    for i in range(1,num_betas):\n",
    "        beta = 1 - i/num_betas\n",
    "        res_map[:,:,i] = h_res**beta\n",
    "        algo[:,:,i] = np.abs(J_res - res_map[:,:,i])\n",
    "        \n",
    "    mapa_indices = np.argmin(algo,axis=2)\n",
    "\n",
    "    C = np.zeros_like(res_map)\n",
    "    for i in range(1,num_betas):\n",
    "        #Aquí creamos las distintas clasificaciones del gradiente según la dirección que toma cada pixel\n",
    "        #Guardaremos en Ci los pixeles de G en las posiciones donde nuestro mapa de direcciones tenga el valor de la direccion i\n",
    "        #En otro caso será 0\n",
    "        C[:,:,i] = res_map[:,:,i] * (mapa_indices == i)\n",
    "        \n",
    "    \n",
    "    T = np.sum(C, axis = 2)\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 1140)\n",
      "(760, 1140)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"trafico.png\",0)\n",
    "J = ajustar_tonalidad(img,w_group=2)\n",
    "H = cv2.imread(\"pencil1.jpg\",0)\n",
    "T = obtener_textura_lapiz2(img,H,J,100)\n",
    "T2 = obtener_textura_lapiz(img,H,J)\n",
    "cv2.imshow('Texturas', T)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow('Texturas2', T2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "S = obtener_trazado(img,8,8)\n",
    "R = np.multiply(S,T)\n",
    "R2 = np.multiply(S,T2)\n",
    "cv2.imshow('Dibujo final', R)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imshow('Dibujo final 2', R2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
